{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Машинное обучение, ФКН ВШЭ\n",
    "\n",
    "# Практическое задание 1\n",
    "\n",
    "## Общая информация\n",
    "\n",
    "Срок сдачи: 28.10.2023 14:40\n",
    "\n",
    "### О задании\n",
    "\n",
    "Практическое задание 1 посвящено изучению основных библиотек для анализа данных, а также линейных моделей и методов их обучения. Вы научитесь:\n",
    " * применять библиотеки NumPy и Pandas для осуществления желаемых преобразований;\n",
    " * подготавливать данные для обучения линейных моделей;\n",
    " * обучать линейную, Lasso и Ridge-регрессии при помощи модуля scikit-learn;\n",
    " * реализовывать обычный и стохастический градиентные спуски;\n",
    " * обучать линейную регрессию для произвольного функционала качества.\n",
    " \n",
    "\n",
    "### Оценивание и штрафы\n",
    "\n",
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимально допустимая оценка за работу — 10 баллов. Кроме того, некоторые из заданий являются опциональными (необязательными), однако за их выполнение можно получить дополнительные баллы.\n",
    "\n",
    "Сдавать задание после указанного срока сдачи нельзя. При выставлении неполного балла за задание в связи с наличием ошибок на усмотрение проверяющего предусмотрена возможность исправить работу на указанных в ответном письме условиях.\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов. Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце Вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник). \n",
    "\n",
    "Неэффективная реализация кода может негативно отразиться на оценке.\n",
    "\n",
    "\n",
    "### Формат сдачи\n",
    "Для сдачи задания переименуйте получившийся файл \\*.ipynb в соответствии со следующим форматом: *HW1_Username.ipynb*, где *Username* — Ваша фамилия и инициалы на латинице (например, *HW1_IvanovII.ipynb*). Далее отправьте этот файл на bobrovskaya_op@surgu.ru или Smorodinov-1990@mail.ru."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Библиотеки для анализа данных\n",
    "\n",
    "### NumPy\n",
    "\n",
    "Во всех заданиях данного раздела запрещено использовать циклы  и list comprehensions. Под вектором и матрицей в данных заданиях понимается одномерный и двумерный numpy.array соответственно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-26T06:03:38.929891100Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. (0.2 балла)** Реализуйте функцию, возвращающую максимальный элемент в векторе x среди элементов, перед которыми стоит нулевой. Для x = np.array([6, 2, 0, 3, 0, 0, 5, 7, 0]) ответом является 5. Если нулевых элементов нет, функция должна возвращать None.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-26T06:03:38.929891100Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "None\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "def max_after_zero(x):\n",
    "    zero_indices = np.where(x == 0)[0]\n",
    "    \n",
    "    if len(zero_indices) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Фильтруем индексы, чтобы не выходить за пределы массива\n",
    "    valid_indices = zero_indices[zero_indices + 1 < len(x)]\n",
    "    \n",
    "    # Получаем элементы, которые идут сразу после нулевых\n",
    "    after_zero_elements = x[valid_indices + 1]\n",
    "    \n",
    "    return np.max(after_zero_elements) if len(after_zero_elements) > 0 else None\n",
    "\n",
    "x = np.array([6, 2, 0, 3, 0, 0, 5, 7, 0])\n",
    "y = np.array([6, 2, 1, 3, 32, 2, 5, 7, 6])\n",
    "z = np.array([10,10,10,5,5,0,0,0,10,0,2,11,0,13])\n",
    "print(max_after_zero(x))\n",
    "print(max_after_zero(y))\n",
    "print(max_after_zero(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. (0.2 балла)** Реализуйте функцию, принимающую на вход матрицу и некоторое число и возвращающую ближайший к числу элемент матрицы. Например: для X = np.arange(0,10).reshape((2, 5)) и v = 3.6 ответом будет 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-26T06:03:38.929891100Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Матрица:\n",
      "[[0 1 2 3 4]\n",
      " [5 6 7 8 9]]\n",
      "Число:\n",
      "3.6\n",
      "Ближайший к числу элемент матрицы:\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "def find_closest_element(matrix, value):\n",
    "    diff = np.abs(matrix - value)\n",
    "    \n",
    "    # Находим индекс элемента с минимальной разницей\n",
    "    min_index = np.argmin(diff)\n",
    "\n",
    "    # Возвращаем элемент матрицы, соответствующий найденному индексу\n",
    "    return matrix.flatten()[min_index]\n",
    "\n",
    "X = np.arange(0, 10).reshape((2, 5))\n",
    "v = 3.6\n",
    "print ('Матрица:', X, 'Число:', v, 'Ближайший к числу элемент матрицы:', find_closest_element(X, v), sep='\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. (0.2 балла)** Реализуйте функцию scale(X), которая принимает на вход матрицу и масштабирует каждый ее столбец (вычитает выборочное среднее и делит на стандартное отклонение). Убедитесь, что в функции не будет происходить деления на ноль. Протестируйте на случайной матрице (для её генерации можно использовать, например, функцию [numpy.random.randint](http://docs.scipy.org/doc/numpy/reference/generated/numpy.random.randint.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-26T06:03:38.929891100Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Matrix:\n",
      " [[55 16 37 23 68]\n",
      " [97 69 85 10 15]\n",
      " [96 72 58 69 79]\n",
      " [92  2 19 58 35]\n",
      " [18 89 66 18 19]]\n",
      "\n",
      "Scaled Matrix:\n",
      " [[-0.53547273 -0.98439378 -0.69763315 -0.5381275   0.95885206]\n",
      " [ 0.81933779  0.56837022  1.3952663  -1.09333841 -1.09030758]\n",
      " [ 0.78708039  0.65626252  0.21801036  1.42646496  1.38414934]\n",
      " [ 0.65805082 -1.39455785 -1.48247045  0.95667111 -0.31703979]\n",
      " [-1.72899628  1.15431889  0.56682694 -0.75167016 -0.93565403]]\n"
     ]
    }
   ],
   "source": [
    "def scale(X):\n",
    "    # Вычисляем среднее и стандартное отклонение для каждого столбца\n",
    "    mean = np.mean(X, axis=0)\n",
    "    std = np.std(X, axis=0)\n",
    "    \n",
    "    # Избегаем деления на ноль: если std = 0, заменяем его на 1\n",
    "    std_revised = np.where(std == 0, 1, std)\n",
    "    \n",
    "    # Масштабируем столбцы матрицы\n",
    "    X_scaled = (X - mean) / std_revised\n",
    "    \n",
    "    return X_scaled\n",
    "\n",
    "X = np.random.randint(0, 100, size=(5, 5))\n",
    "print(\"Original Matrix:\\n\", X)\n",
    "print(\"\\nScaled Matrix:\\n\", scale(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**4. (0.2 балла)** Реализуйте функцию, которая для заданной матрицы находит:\n",
    " - определитель\n",
    " - след\n",
    " - наименьший и наибольший элементы\n",
    " - норму Фробениуса\n",
    " - собственные числа\n",
    " - обратную матрицу\n",
    "\n",
    "Для тестирования сгенерируйте матрицу с элементами из нормального распределения $\\mathcal{N}$(10,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-26T06:03:38.945551500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Matrix:\n",
      " [[11.30714275  8.39251677 10.18463386]\n",
      " [10.25988279 10.78182287  8.76304929]\n",
      " [ 8.67954339 10.52194157 10.29698467]]\n",
      "Определитель: 110.82848213702505\n",
      "След: 32.38595029929293\n",
      "Минимальный элемент: 8.392516765438772\n",
      "Максимальный элемент: 11.307142754282427\n",
      "Фробениусова норма: 29.872899676233953\n",
      "Собственные значения: [29.73133772+0.j          1.32730629+1.40211395j  1.32730629-1.40211395j]\n",
      "Обратная матрица: [[ 0.1697756   0.18717667 -0.32721625]\n",
      " [-0.26695836  0.2529269   0.04879703]\n",
      " [ 0.12968316 -0.41622768  0.32307013]]\n"
     ]
    }
   ],
   "source": [
    "def matrix_operations(matrix):\n",
    "    determinant = np.linalg.det(matrix)\n",
    "    trace = np.trace(matrix)\n",
    "\n",
    "    min_element = np.min(matrix)\n",
    "    max_element = np.max(matrix)\n",
    "\n",
    "    frobenius_norm = np.linalg.norm(matrix, 'fro')\n",
    "    eigenvalues = np.linalg.eigvals(matrix)\n",
    "    inverse_matrix = np.linalg.inv(matrix)\n",
    "\n",
    "    return {\n",
    "        \"Определитель\": determinant,\n",
    "        \"След\": trace,\n",
    "        \"Минимальный элемент\": min_element,\n",
    "        \"Максимальный элемент\": max_element,\n",
    "        \"Фробениусова норма\": frobenius_norm,\n",
    "        \"Собственные значения\": eigenvalues,\n",
    "        \"Обратная матрица\": inverse_matrix\n",
    "    }\n",
    "\n",
    "random_matrix = np.random.normal(10, 1, (3, 3))\n",
    "\n",
    "print(\"Original Matrix:\\n\", random_matrix)\n",
    "\n",
    "matrix_props = matrix_operations(random_matrix)\n",
    "\n",
    "for key, value in matrix_props.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. (0.2 балла)** Повторите 100 раз следующий эксперимент: сгенерируйте две матрицы размера 10×10 из стандартного нормального распределения, перемножьте их (как матрицы) и найдите максимальный элемент. Какое среднее значение по экспериментам у максимальных элементов? 95-процентная квантиль?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-26T06:03:38.945551500Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее максимальное значение: 8.359534676021545\n",
      "95-й перцентиль: 12.144158799143964\n"
     ]
    }
   ],
   "source": [
    "def calculate_max_elements(num_experiments):\n",
    "    max_elements = []\n",
    "\n",
    "    for _ in range(num_experiments):\n",
    "        matrix1 = np.random.randn(10, 10)\n",
    "        matrix2 = np.random.randn(10, 10)\n",
    "\n",
    "        result_matrix = np.dot(matrix1, matrix2)\n",
    "        max_element = np.max(result_matrix)\n",
    "        max_elements.append(max_element)\n",
    "    \n",
    "    mean_max_element = np.mean(max_elements)\n",
    "    quantile_95 = np.percentile(max_elements, 95)\n",
    "\n",
    "    return mean_max_element, quantile_95\n",
    "\n",
    "num_experiments = 100\n",
    "mean_max, quantile_95 = calculate_max_elements(num_experiments)\n",
    "\n",
    "print(f\"Среднее максимальное значение: {mean_max}\")\n",
    "print(f\"95-й перцентиль: {quantile_95}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas\n",
    "\n",
    "![](https://metrouk2.files.wordpress.com/2015/10/panda.jpg)\n",
    "\n",
    "#### Ответьте на вопросы о данных по авиарейсам в США за январь-апрель 2008 года.\n",
    "\n",
    "[Данные](https://www.kaggle.com/datasets/prajitdatta/data-stories-of-us-airlines)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-26T06:03:38.945551500Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. (0.3 балла)** Какая из причин отмены рейса (`CancellationCode`) была самой частой? (расшифровки кодов можно найти в описании данных)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-26T06:03:38.945551500Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наиболее часто встречающийся код отмены: B\n"
     ]
    }
   ],
   "source": [
    "def find_most_common_cancellation_code(data_frame):\n",
    "    df = pd.read_csv(data_frame, low_memory=False)\n",
    "    most_common_cancellation_code = df['CancellationCode'].mode().values[0]\n",
    "    return most_common_cancellation_code\n",
    "\n",
    "file_path = 'airline_dec_2008_50k.csv'\n",
    "\n",
    "result = find_most_common_cancellation_code(file_path)\n",
    "\n",
    "print(f\"Наиболее часто встречающийся код отмены: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. (0.3 балла)** Найдите среднее, минимальное и максимальное расстояние, пройденное самолетом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-26T06:03:38.945551500Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее расстояние: 572.15812\n",
      "Минимальное расстояние: 30\n",
      "Максимальное расстояние: 3303\n"
     ]
    }
   ],
   "source": [
    "def calculate_distance_statistics(data_frame):\n",
    "    df = pd.read_csv(data_frame, low_memory=False)\n",
    "\n",
    "    mean_distance = df['Distance'].mean()\n",
    "    min_distance = df['Distance'].min()\n",
    "    max_distance = df['Distance'].max()\n",
    "\n",
    "    return mean_distance, min_distance, max_distance\n",
    "\n",
    "file_path = 'airline_dec_2008_50k.csv'\n",
    "\n",
    "mean_dist, min_dist, max_dist = calculate_distance_statistics(file_path)\n",
    "\n",
    "print(f\"Среднее расстояние: {mean_dist}\")\n",
    "print(f\"Минимальное расстояние: {min_dist}\")\n",
    "print(f\"Максимальное расстояние: {max_dist}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. (0.3 балла)** Не выглядит ли подозрительным минимальное пройденное расстояние? В какие дни и на каких рейсах оно было? Какое расстояние было пройдено этими же рейсами в другие дни?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-26T06:03:38.945551500Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Подозрительные рейсы с минимальным расстоянием:\n",
      "       Year  Month  DayofMonth  FlightNum Origin Dest  Distance\n",
      "16788  2008     12          31       5613    SFO  SJC        30\n",
      "\n",
      "Расстояния этих же рейсов в другие дни:\n",
      "       Year  Month  DayofMonth  FlightNum Origin Dest  Distance\n",
      "433    2008     12           1       5613    CVG  MEM       403\n",
      "15982  2008     12          28       5613    MDT  CVG       429\n",
      "19656  2008     12           1       5613    MDT  CVG       429\n",
      "22266  2008     12           2       5613    MDT  CVG       429\n",
      "24371  2008     12           2       5613    CVG  MEM       403\n",
      "25164  2008     12           3       5613    MDT  CVG       429\n",
      "27058  2008     12           3       5613    CVG  MEM       403\n",
      "28344  2008     12           4       5613    MDT  CVG       429\n",
      "29541  2008     12           4       5613    CVG  MEM       403\n",
      "29882  2008     12           5       5613    MDT  CVG       429\n",
      "32027  2008     12           5       5613    CVG  MEM       403\n",
      "32300  2008     12           6       5613    MDT  CVG       429\n",
      "34265  2008     12           7       5613    MDT  CVG       429\n",
      "35642  2008     12           7       5613    CVG  MEM       403\n",
      "36028  2008     12           8       5613    MDT  CVG       429\n",
      "38133  2008     12           8       5613    CVG  MEM       403\n",
      "38515  2008     12           9       5613    MDT  CVG       429\n",
      "40787  2008     12          10       5613    MDT  CVG       429\n",
      "42824  2008     12          10       5613    CVG  MEM       403\n",
      "43399  2008     12          11       5613    MDT  CVG       429\n",
      "45314  2008     12          11       5613    CVG  MEM       403\n",
      "46374  2008     12          12       5613    MDT  CVG       429\n",
      "48284  2008     12          12       5613    CVG  MEM       403\n",
      "48617  2008     12          13       5613    MDT  CVG       429\n",
      "Еще пару подозрительных рейсов\n",
      "\n",
      "       Year  Month  DayofMonth  FlightNum Origin Dest  Distance\n",
      "8      2008     12           1       7065    ORD  MKE        67\n",
      "22     2008     12           1       3033    LAX  SBA        89\n",
      "23     2008     12           1       2732    MKE  ATW        96\n",
      "25     2008     12           1       2623    MKE  MSN        74\n",
      "35     2008     12           1       7065    MKE  ORD        67\n",
      "...     ...    ...         ...        ...    ...  ...       ...\n",
      "49929  2008     12          13       3039    LAX  SBA        89\n",
      "49940  2008     12          13       5720    SFO  MOD        78\n",
      "49941  2008     12          13       4104    MKE  ORD        67\n",
      "49972  2008     12          13       7091    ORD  MKE        67\n",
      "49983  2008     12          13       5781    ACV  CEC        56\n",
      "\n",
      "[999 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "file_path = 'airline_dec_2008_50k.csv'  # Укажите путь к файлу\n",
    "df = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "min_distance = df['Distance'].min()\n",
    "\n",
    "suspicious_flights = df[df['Distance'] == min_distance]\n",
    "\n",
    "print(\"Подозрительные рейсы с минимальным расстоянием:\")\n",
    "print(suspicious_flights[['Year', 'Month', 'DayofMonth', 'FlightNum', 'Origin', 'Dest', 'Distance']])\n",
    "\n",
    "# Проверяем, какое расстояние пройдено этими же рейсами в другие дни\n",
    "same_flights_other_days = df[(df['FlightNum'].isin(suspicious_flights['FlightNum'])) &\n",
    "                             (~df.index.isin(suspicious_flights.index))]\n",
    "\n",
    "print(\"\\nРасстояния этих же рейсов в другие дни:\")\n",
    "print(same_flights_other_days[['Year', 'Month', 'DayofMonth', 'FlightNum', 'Origin', 'Dest', 'Distance']])\n",
    "\n",
    "suspicious_flights2 = df[df['Distance'] < 100]\n",
    "print(f\"Еще пару подозрительных рейсов\\n\")\n",
    "print(suspicious_flights2[['Year', 'Month', 'DayofMonth', 'FlightNum', 'Origin', 'Dest', 'Distance']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9. (0.3 балла)** Из какого аэропорта было произведено больше всего вылетов? В каком городе он находится?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-26T06:03:38.945551500Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Больше всего вылетов было произведено из аэропорта: ORD\n",
      "Количество вылетов: 3056\n",
      "Аэропорт находится в городе: Chicago, IL\n"
     ]
    }
   ],
   "source": [
    "file_path = 'airline_dec_2008_50k.csv'  # Укажите путь к файлу\n",
    "df = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "most_departures_airport = df['Origin'].value_counts().idxmax()\n",
    "most_departures_count = df['Origin'].value_counts().max()\n",
    "\n",
    "print(f\"Больше всего вылетов было произведено из аэропорта: {most_departures_airport}\")\n",
    "print(f\"Количество вылетов: {most_departures_count}\")\n",
    "\n",
    "airport_city_mapping = {\n",
    "    'ATL': 'Atlanta, GA',\n",
    "    'LAX': 'Los Angeles, CA',\n",
    "    'ORD': 'Chicago, IL',\n",
    "}\n",
    "\n",
    "most_departures_city = airport_city_mapping.get(most_departures_airport, \"Unknown City\")\n",
    "print(f\"Аэропорт находится в городе: {most_departures_city}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10. (0.3 балла)** Найдите для каждого аэропорта среднее время полета (`AirTime`) по всем вылетевшим из него рейсам. Какой аэропорт имеет наибольшее значение этого показателя?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-26T06:03:38.961176600Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Origin\n",
      "ABE    95.171429\n",
      "ABI    31.945946\n",
      "ABQ    78.874439\n",
      "ABY    34.076923\n",
      "ACT    26.461538\n",
      "         ...    \n",
      "TYS    91.580645\n",
      "VLD    43.000000\n",
      "VPS    65.955556\n",
      "XNA    71.073394\n",
      "YUM    46.280000\n",
      "Name: AirTime, Length: 260, dtype: float64\n",
      "Аэропорт с наибольшим средним временем полета: PSE\n",
      "Среднее время полета для этого аэропорта: 182.12 минут\n"
     ]
    }
   ],
   "source": [
    "file_path = 'airline_dec_2008_50k.csv'\n",
    "df = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "# Убираем пропущенные значения в столбце 'AirTime'\n",
    "df = df.dropna(subset=['AirTime'])\n",
    "\n",
    "# Вычисляем среднее время полета для каждого аэропорта отправления\n",
    "mean_airtime_by_airport = df.groupby('Origin')['AirTime'].mean()\n",
    "\n",
    "max_mean_airtime_airport = mean_airtime_by_airport.idxmax()\n",
    "max_mean_airtime_value = mean_airtime_by_airport.max()\n",
    "\n",
    "mean_airtime_by_airport, max_mean_airtime_airport, max_mean_airtime_value\n",
    "\n",
    "print(mean_airtime_by_airport)\n",
    "print(f\"Аэропорт с наибольшим средним временем полета: {max_mean_airtime_airport}\")\n",
    "print(f\"Среднее время полета для этого аэропорта: {max_mean_airtime_value:.2f} минут\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**11. (0.5 балла)** Найдите аэропорт, у которого наибольшая доля задержанных (`DepDelay > 0`) рейсов. Исключите при этом из рассмотрения аэропорты, из которых было отправлено меньше 1000 рейсов (используйте функцию `filter` после `groupby`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-26T06:03:38.961176600Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Origin\n",
      "ABE    0.230769\n",
      "ABI    0.108108\n",
      "ABQ    0.135965\n",
      "ABY    0.000000\n",
      "ACT    0.153846\n",
      "         ...   \n",
      "TYS    0.212121\n",
      "VLD    0.230769\n",
      "VPS    0.127660\n",
      "XNA    0.223214\n",
      "YUM    0.160000\n",
      "Length: 249, dtype: float64\n",
      "Аэропорт с наибольшей долей задержанных рейсов: JNU\n",
      "Доля задержанных рейсов для этого аэропорта: 63.33%\n"
     ]
    }
   ],
   "source": [
    "file_path = 'airline_dec_2008_50k.csv'  # Укажите путь к файлу\n",
    "df = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "# Убираем пропущенные значения в столбцах 'DepDelay' и 'Origin'\n",
    "df = df.dropna(subset=['DepDelay', 'Origin'])\n",
    "\n",
    "# Определяем функцию для расчета доли задержанных рейсов\n",
    "def calculate_delay_ratio(group):\n",
    "    total_flights = len(group)\n",
    "    delayed_flights = (group['DepDelay'] > 0).sum()\n",
    "    delay_ratio = delayed_flights / total_flights\n",
    "    return delay_ratio\n",
    "\n",
    "# Группируем по аэропортам отправления\n",
    "grouped = df.groupby('Origin')\n",
    "\n",
    "# Фильтруем группы по количеству рейсов\n",
    "filtered_group = grouped.filter(lambda x: len(x) >= 10)\n",
    "\n",
    "# Вычисляем долю задержанных рейсов\n",
    "delay_ratios = filtered_group.groupby('Origin').apply(calculate_delay_ratio, include_groups=False)\n",
    "\n",
    "# Находим аэропорт с наибольшей долей задержанных рейсов\n",
    "max_delay_airport = delay_ratios.idxmax()\n",
    "max_delay_ratio = delay_ratios.max()\n",
    "\n",
    "# Выводим долю задержек для каждого аэропорта\n",
    "print(delay_ratios)\n",
    "\n",
    "# Выводим аэропорт с наибольшей долей задержанных рейсов и долю задержек\n",
    "print(f\"Аэропорт с наибольшей долей задержанных рейсов: {max_delay_airport}\")\n",
    "print(f\"Доля задержанных рейсов для этого аэропорта: {max_delay_ratio:.2%}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Линейная регрессия\n",
    "\n",
    "В этой части мы разберемся с линейной регрессией, способами её обучения и измерением качества ее прогнозов. \n",
    "\n",
    "Будем рассматривать датасет из предыдущей части задания для предсказания времени задержки отправления рейса в минутах (DepDelay). Отметим, что под задержкой подразумевается не только опоздание рейса относительно планируемого времени вылета, но и отправление до планируемого времени.\n",
    "\n",
    "### Подготовка данных\n",
    "\n",
    "**12. (0.5 балла)** Считайте выборку из файла при помощи функции pd.read_csv и ответьте на следующие вопросы:\n",
    "   - Имеются ли в данных пропущенные значения?\n",
    "   - Сколько всего пропущенных элементов в таблице \"объект-признак\"?\n",
    "   - Сколько объектов имеют хотя бы один пропуск?\n",
    "   - Сколько признаков имеют хотя бы одно пропущенное значение?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-26T06:03:38.961176600Z"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Имеются ли в данных пропущенные значения?: True\n",
      "Сколько всего пропущенных элементов в таблице 'объект-признак'?: 411549\n",
      "Сколько объектов имеют хотя бы один пропуск?: 50000\n",
      "Сколько признаков имеют хотя бы одно пропущенное значение?: 15\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('airline_dec_2008_50k.csv', low_memory=False)\n",
    "\n",
    "any_null_values = df.isnull().any().any()\n",
    "total_null_elements = df.isnull().sum().sum()\n",
    "objects_with_nulls = df.isnull().any(axis=1).sum()\n",
    "features_with_nulls = df.isnull().any().sum()\n",
    "\n",
    "print(f\"Имеются ли в данных пропущенные значения?: {any_null_values}\")\n",
    "print(f\"Сколько всего пропущенных элементов в таблице 'объект-признак'?: {total_null_elements}\")\n",
    "print(f\"Сколько объектов имеют хотя бы один пропуск?: {objects_with_nulls}\")\n",
    "print(f\"Сколько признаков имеют хотя бы одно пропущенное значение?: {features_with_nulls}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как вы понимаете, также не имеет смысла рассматривать при решении поставленной задачи объекты с пропущенным значением целевой переменной. В связи с этим ответьте на следующие вопросы и выполните соответствующие действия:\n",
    "- Имеются ли пропущенные значения в целевой переменной?\n",
    "- Проанализируйте объекты с пропущенными значениями целевой переменной. Чем вызвано это явление? Что их объединяет? Можно ли в связи с этим, на ваш взгляд, исключить какие-то признаки из рассмотрения? Обоснуйте свою точку зрения.\n",
    "\n",
    "Исключите из выборки объектыф **с пропущенным значением целевой переменной и со значением целевой переменной, равным 0**, а также при необходимости исключите признаки в соответствии с вашим ответом на последний вопрос из списка и выделите целевую переменную в отдельный вектор, исключив её из матрицы \"объект-признак\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-26T06:03:38.961176600Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Имеются ли пропущенные значения в целевой переменной?: 0        False\n",
      "1        False\n",
      "2        False\n",
      "3        False\n",
      "4        False\n",
      "         ...  \n",
      "49995    False\n",
      "49996    False\n",
      "49997    False\n",
      "49998    False\n",
      "49999    False\n",
      "Name: Cancelled, Length: 50000, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('airline_dec_2008_50k.csv', low_memory=False)\n",
    "\n",
    "# Проверка на наличие пропущенных значений в целевой переменной\n",
    "missing_target_values = df['Cancelled'].isnull()\n",
    "# missing_target_values = df['Cancelled'].isnull().sum()\n",
    "\n",
    "# Фильтрация данных: удаление строк с пропущенными значениями и неотмененными рейсами\n",
    "df = df.dropna(subset=['Cancelled'])\n",
    "df = df[df['Cancelled'] != 0]\n",
    "\n",
    "# Удаление ненужного столбца\n",
    "df = df.drop(columns=['CancellationCode', 'Cancelled'])\n",
    "\n",
    "# Вывод сообщения о наличии пропущенных значений\n",
    "print(f\"Имеются ли пропущенные значения в целевой переменной?: {missing_target_values}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**13. (0.5 балла)** Обратите внимание, что признаки DepTime, CRSDepTime, ArrTime, CRSArrTime приведены в формате hhmm, в связи с чем будет не вполне корректно рассматривать их как вещественные.\n",
    "\n",
    "Преобразуйте каждый признак FeatureName из указанных в пару новых признаков FeatureName\\_Hour, FeatureName\\_Minute, разделив каждое из значений на часы и минуты. Не забудьте при этом исключить исходный признак из выборки. В случае, если значение признака отсутствует, значения двух новых признаков, его заменяющих, также должны отсутствовать. \n",
    "\n",
    "Например, признак DepTime необходимо заменить на пару признаков DepTime_Hour, DepTime_Minute. При этом, например, значение 155 исходного признака будет преобразовано в значения 1 и 55 признаков DepTime_Hour, DepTime_Minute соответственно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-26T06:03:38.961176600Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0  Year  Month  DayofMonth  DayOfWeek UniqueCarrier  \\\n",
      "0               1  2008     12           1          1            WN   \n",
      "1               2  2008     12           1          1            US   \n",
      "2               3  2008     12           1          1            MQ   \n",
      "3               4  2008     12           1          1            EV   \n",
      "4               5  2008     12           1          1            NW   \n",
      "...           ...   ...    ...         ...        ...           ...   \n",
      "49995       49996  2008     12          13          6            YV   \n",
      "49996       49997  2008     12          13          6            CO   \n",
      "49997       49998  2008     12          13          6            WN   \n",
      "49998       49999  2008     12          13          6            AA   \n",
      "49999       50000  2008     12          13          6            MQ   \n",
      "\n",
      "       FlightNum TailNum  ActualElapsedTime  CRSElapsedTime  ...  \\\n",
      "0             16  N366SW                NaN              60  ...   \n",
      "1           2122     NaN                NaN              70  ...   \n",
      "2           3155  N807MQ                NaN              85  ...   \n",
      "3           4980  N978EV                NaN              87  ...   \n",
      "4           1406  N752NW                NaN              87  ...   \n",
      "...          ...     ...                ...             ...  ...   \n",
      "49995       2891  N925FJ               55.0              54  ...   \n",
      "49996        414  N78511               61.0              66  ...   \n",
      "49997        505  N240WN               80.0              90  ...   \n",
      "49998       1336  N4WBAA               93.0              95  ...   \n",
      "49999       4673  N826MQ               89.0              95  ...   \n",
      "\n",
      "       SecurityDelay  LateAircraftDelay  DepTime_Hour DepTime_Minute  \\\n",
      "0                NaN                NaN           NaN            NaN   \n",
      "1                NaN                NaN           NaN            NaN   \n",
      "2                NaN                NaN           NaN            NaN   \n",
      "3                NaN                NaN           NaN            NaN   \n",
      "4                NaN                NaN           NaN            NaN   \n",
      "...              ...                ...           ...            ...   \n",
      "49995            NaN                NaN           8.0            5.0   \n",
      "49996            NaN                NaN           8.0            5.0   \n",
      "49997            NaN                NaN           8.0            5.0   \n",
      "49998            NaN                NaN           8.0            5.0   \n",
      "49999            NaN                NaN           8.0            6.0   \n",
      "\n",
      "      CRSDepTime_Hour  CRSDepTime_Minute  ArrTime_Hour  ArrTime_Minute  \\\n",
      "0                  10                  0           NaN             NaN   \n",
      "1                  10                  0           NaN             NaN   \n",
      "2                  10                  0           NaN             NaN   \n",
      "3                  10                  0           NaN             NaN   \n",
      "4                  10                  0           NaN             NaN   \n",
      "...               ...                ...           ...             ...   \n",
      "49995               8                 10           9.0             0.0   \n",
      "49996               8                 10           9.0             6.0   \n",
      "49997               8                 10           9.0            25.0   \n",
      "49998               8                 10           9.0            38.0   \n",
      "49999               8                  0           9.0            35.0   \n",
      "\n",
      "       CRSArrTime_Hour CRSArrTime_Minute  \n",
      "0                   11                 0  \n",
      "1                   11                10  \n",
      "2                   11                25  \n",
      "3                   12                27  \n",
      "4                   12                27  \n",
      "...                ...               ...  \n",
      "49995                9                 4  \n",
      "49996                9                16  \n",
      "49997                9                40  \n",
      "49998                9                45  \n",
      "49999                9                35  \n",
      "\n",
      "[50000 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Загрузка данных из файла\n",
    "file_path = './airline_dec_2008_50k.csv'\n",
    "data = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "# Список признаков для преобразования\n",
    "time_features = ['DepTime', 'CRSDepTime', 'ArrTime', 'CRSArrTime']\n",
    "\n",
    "for feature in time_features:\n",
    "    # Функция для извлечения часов и минут\n",
    "    def extract_hour_minute(value):\n",
    "        if pd.isnull(value):\n",
    "            return pd.Series([np.nan, np.nan])\n",
    "        try:\n",
    "            # Преобразуем значение в строку, удаляем десятичные точки и заполняем нулями слева до 4 символов\n",
    "            value_str = f\"{int(value):04d}\"\n",
    "            hour = int(value_str[:-2])\n",
    "            minute = int(value_str[-2:])\n",
    "            return pd.Series([hour, minute])\n",
    "        except:\n",
    "            return pd.Series([np.nan, np.nan])\n",
    "    \n",
    "    # Применяем функцию к каждому значению признака\n",
    "    data[[f\"{feature}_Hour\", f\"{feature}_Minute\"]] = data[feature].apply(extract_hour_minute)\n",
    "    \n",
    "    # Удаляем исходный признак\n",
    "    data.drop(columns=feature, inplace=True)\n",
    "\n",
    "# Для проверки результатов можно вывести первые несколько строк\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**14. (0.5 балла)** Некоторые из признаков, отличных от целевой переменной, могут оказывать чересчур значимое влияние на прогноз, поскольку по своему смыслу содержат большую долю информации о значении целевой переменной. Изучите описание датасета и исключите признаки, сильно коррелирующие с ответами. Ваш выбор признаков для исключения из выборки обоснуйте. Кроме того, исключите признаки TailNum и Year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-26T06:03:38.961176600Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Корреляция с целевой переменной (Cancelled):\n",
      "Cancelled            1.000000\n",
      "CRSArrTime           0.695137\n",
      "DayofMonth           0.660181\n",
      "CRSDepTime           0.602015\n",
      "DepTime              0.306075\n",
      "                       ...   \n",
      "SecurityDelay             NaN\n",
      "LateAircraftDelay         NaN\n",
      "UniqueCarrier_nan         NaN\n",
      "Origin_nan                NaN\n",
      "Dest_nan                  NaN\n",
      "Name: Cancelled, Length: 598, dtype: float64\n",
      "\n",
      "Признаки с корреляцией выше 0.5: ['Cancelled', 'CRSArrTime', 'DayofMonth', 'CRSDepTime', 'Unnamed: 0']\n",
      "\n",
      "После удаления высоко коррелированных признаков: ['Month', 'DayOfWeek', 'DepTime', 'ArrTime', 'FlightNum', 'ActualElapsedTime', 'CRSElapsedTime', 'AirTime', 'ArrDelay', 'DepDelay', 'Distance', 'TaxiIn', 'TaxiOut', 'Diverted', 'CarrierDelay', 'WeatherDelay', 'NASDelay', 'SecurityDelay', 'LateAircraftDelay', 'UniqueCarrier_9E', 'UniqueCarrier_AA', 'UniqueCarrier_AS', 'UniqueCarrier_B6', 'UniqueCarrier_CO', 'UniqueCarrier_DL', 'UniqueCarrier_EV', 'UniqueCarrier_F9', 'UniqueCarrier_FL', 'UniqueCarrier_HA', 'UniqueCarrier_MQ', 'UniqueCarrier_NW', 'UniqueCarrier_OH', 'UniqueCarrier_OO', 'UniqueCarrier_UA', 'UniqueCarrier_US', 'UniqueCarrier_WN', 'UniqueCarrier_XE', 'UniqueCarrier_YV', 'UniqueCarrier_nan', 'Origin_ABE', 'Origin_ABI', 'Origin_ABQ', 'Origin_ABY', 'Origin_ACT', 'Origin_ACV', 'Origin_ADK', 'Origin_ADQ', 'Origin_AEX', 'Origin_AGS', 'Origin_ALB', 'Origin_ALO', 'Origin_AMA', 'Origin_ANC', 'Origin_ASE', 'Origin_ATL', 'Origin_ATW', 'Origin_AUS', 'Origin_AVL', 'Origin_AVP', 'Origin_AZO', 'Origin_BDL', 'Origin_BET', 'Origin_BFL', 'Origin_BGM', 'Origin_BGR', 'Origin_BHM', 'Origin_BIL', 'Origin_BIS', 'Origin_BMI', 'Origin_BNA', 'Origin_BOI', 'Origin_BOS', 'Origin_BQK', 'Origin_BQN', 'Origin_BRO', 'Origin_BRW', 'Origin_BTM', 'Origin_BTR', 'Origin_BTV', 'Origin_BUF', 'Origin_BUR', 'Origin_BWI', 'Origin_BZN', 'Origin_CAE', 'Origin_CAK', 'Origin_CDC', 'Origin_CDV', 'Origin_CEC', 'Origin_CHA', 'Origin_CHO', 'Origin_CHS', 'Origin_CIC', 'Origin_CID', 'Origin_CLD', 'Origin_CLE', 'Origin_CLL', 'Origin_CLT', 'Origin_CMH', 'Origin_CMI', 'Origin_CMX', 'Origin_COD', 'Origin_COS', 'Origin_CPR', 'Origin_CRP', 'Origin_CRW', 'Origin_CSG', 'Origin_CVG', 'Origin_CWA', 'Origin_DAB', 'Origin_DAL', 'Origin_DAY', 'Origin_DBQ', 'Origin_DCA', 'Origin_DEN', 'Origin_DFW', 'Origin_DHN', 'Origin_DLH', 'Origin_DRO', 'Origin_DSM', 'Origin_DTW', 'Origin_EGE', 'Origin_EKO', 'Origin_ELM', 'Origin_ELP', 'Origin_ERI', 'Origin_EUG', 'Origin_EVV', 'Origin_EWN', 'Origin_EWR', 'Origin_EYW', 'Origin_FAI', 'Origin_FAR', 'Origin_FAT', 'Origin_FAY', 'Origin_FCA', 'Origin_FLG', 'Origin_FLL', 'Origin_FLO', 'Origin_FNT', 'Origin_FSD', 'Origin_FSM', 'Origin_FWA', 'Origin_GCC', 'Origin_GEG', 'Origin_GFK', 'Origin_GGG', 'Origin_GJT', 'Origin_GNV', 'Origin_GPT', 'Origin_GRB', 'Origin_GRK', 'Origin_GRR', 'Origin_GSO', 'Origin_GSP', 'Origin_GTF', 'Origin_GTR', 'Origin_GUC', 'Origin_HDN', 'Origin_HLN', 'Origin_HNL', 'Origin_HOU', 'Origin_HPN', 'Origin_HRL', 'Origin_HSV', 'Origin_HTS', 'Origin_IAD', 'Origin_IAH', 'Origin_ICT', 'Origin_IDA', 'Origin_ILM', 'Origin_IND', 'Origin_IPL', 'Origin_ISP', 'Origin_ITH', 'Origin_ITO', 'Origin_IYK', 'Origin_JAC', 'Origin_JAN', 'Origin_JAX', 'Origin_JFK', 'Origin_JNU', 'Origin_KOA', 'Origin_KTN', 'Origin_LAN', 'Origin_LAS', 'Origin_LAW', 'Origin_LAX', 'Origin_LBB', 'Origin_LCH', 'Origin_LEX', 'Origin_LFT', 'Origin_LGA', 'Origin_LGB', 'Origin_LIH', 'Origin_LIT', 'Origin_LMT', 'Origin_LNK', 'Origin_LRD', 'Origin_LSE', 'Origin_LWS', 'Origin_LYH', 'Origin_MAF', 'Origin_MBS', 'Origin_MCI', 'Origin_MCO', 'Origin_MDT', 'Origin_MDW', 'Origin_MEI', 'Origin_MEM', 'Origin_MFE', 'Origin_MFR', 'Origin_MGM', 'Origin_MHT', 'Origin_MIA', 'Origin_MKE', 'Origin_MLB', 'Origin_MLI', 'Origin_MLU', 'Origin_MOB', 'Origin_MOD', 'Origin_MOT', 'Origin_MQT', 'Origin_MRY', 'Origin_MSN', 'Origin_MSO', 'Origin_MSP', 'Origin_MSY', 'Origin_MTJ', 'Origin_MYR', 'Origin_OAJ', 'Origin_OAK', 'Origin_OGG', 'Origin_OKC', 'Origin_OMA', 'Origin_OME', 'Origin_ONT', 'Origin_ORD', 'Origin_ORF', 'Origin_OTH', 'Origin_OTZ', 'Origin_OXR', 'Origin_PBI', 'Origin_PDX', 'Origin_PFN', 'Origin_PHF', 'Origin_PHL', 'Origin_PHX', 'Origin_PIA', 'Origin_PIH', 'Origin_PIT', 'Origin_PMD', 'Origin_PNS', 'Origin_PSC', 'Origin_PSE', 'Origin_PSG', 'Origin_PSP', 'Origin_PVD', 'Origin_PWM', 'Origin_RAP', 'Origin_RDD', 'Origin_RDM', 'Origin_RDU', 'Origin_RHI', 'Origin_RIC', 'Origin_RKS', 'Origin_RNO', 'Origin_ROA', 'Origin_ROC', 'Origin_ROW', 'Origin_RST', 'Origin_RSW', 'Origin_SAN', 'Origin_SAT', 'Origin_SAV', 'Origin_SBA', 'Origin_SBN', 'Origin_SBP', 'Origin_SCC', 'Origin_SCE', 'Origin_SDF', 'Origin_SEA', 'Origin_SFO', 'Origin_SGF', 'Origin_SGU', 'Origin_SHV', 'Origin_SIT', 'Origin_SJC', 'Origin_SJU', 'Origin_SLC', 'Origin_SMF', 'Origin_SMX', 'Origin_SNA', 'Origin_SPI', 'Origin_SRQ', 'Origin_STL', 'Origin_STT', 'Origin_SUN', 'Origin_SWF', 'Origin_SYR', 'Origin_TEX', 'Origin_TLH', 'Origin_TOL', 'Origin_TPA', 'Origin_TRI', 'Origin_TUL', 'Origin_TUS', 'Origin_TVC', 'Origin_TWF', 'Origin_TXK', 'Origin_TYR', 'Origin_TYS', 'Origin_VLD', 'Origin_VPS', 'Origin_WRG', 'Origin_XNA', 'Origin_YAK', 'Origin_YUM', 'Origin_nan', 'Dest_ABE', 'Dest_ABI', 'Dest_ABQ', 'Dest_ABY', 'Dest_ACT', 'Dest_ACV', 'Dest_ADK', 'Dest_ADQ', 'Dest_AEX', 'Dest_AGS', 'Dest_ALB', 'Dest_ALO', 'Dest_AMA', 'Dest_ANC', 'Dest_ASE', 'Dest_ATL', 'Dest_ATW', 'Dest_AUS', 'Dest_AVL', 'Dest_AVP', 'Dest_AZO', 'Dest_BDL', 'Dest_BET', 'Dest_BFL', 'Dest_BGM', 'Dest_BGR', 'Dest_BHM', 'Dest_BIL', 'Dest_BIS', 'Dest_BMI', 'Dest_BNA', 'Dest_BOI', 'Dest_BOS', 'Dest_BQK', 'Dest_BQN', 'Dest_BRO', 'Dest_BRW', 'Dest_BTM', 'Dest_BTR', 'Dest_BTV', 'Dest_BUF', 'Dest_BUR', 'Dest_BWI', 'Dest_BZN', 'Dest_CAE', 'Dest_CAK', 'Dest_CDC', 'Dest_CDV', 'Dest_CEC', 'Dest_CHA', 'Dest_CHO', 'Dest_CHS', 'Dest_CIC', 'Dest_CID', 'Dest_CLD', 'Dest_CLE', 'Dest_CLL', 'Dest_CLT', 'Dest_CMH', 'Dest_CMI', 'Dest_CMX', 'Dest_COD', 'Dest_COS', 'Dest_CPR', 'Dest_CRP', 'Dest_CRW', 'Dest_CSG', 'Dest_CVG', 'Dest_CWA', 'Dest_DAB', 'Dest_DAL', 'Dest_DAY', 'Dest_DBQ', 'Dest_DCA', 'Dest_DEN', 'Dest_DFW', 'Dest_DHN', 'Dest_DLH', 'Dest_DRO', 'Dest_DSM', 'Dest_DTW', 'Dest_EGE', 'Dest_EKO', 'Dest_ELM', 'Dest_ELP', 'Dest_ERI', 'Dest_EUG', 'Dest_EVV', 'Dest_EWR', 'Dest_FAI', 'Dest_FAR', 'Dest_FAT', 'Dest_FAY', 'Dest_FCA', 'Dest_FLG', 'Dest_FLL', 'Dest_FLO', 'Dest_FNT', 'Dest_FSD', 'Dest_FSM', 'Dest_FWA', 'Dest_GCC', 'Dest_GEG', 'Dest_GFK', 'Dest_GGG', 'Dest_GJT', 'Dest_GNV', 'Dest_GPT', 'Dest_GRB', 'Dest_GRK', 'Dest_GRR', 'Dest_GSO', 'Dest_GSP', 'Dest_GTF', 'Dest_GTR', 'Dest_GUC', 'Dest_HDN', 'Dest_HLN', 'Dest_HNL', 'Dest_HOU', 'Dest_HPN', 'Dest_HRL', 'Dest_HSV', 'Dest_HTS', 'Dest_IAD', 'Dest_IAH', 'Dest_ICT', 'Dest_IDA', 'Dest_ILM', 'Dest_IND', 'Dest_IPL', 'Dest_ISP', 'Dest_ITH', 'Dest_ITO', 'Dest_IYK', 'Dest_JAC', 'Dest_JAN', 'Dest_JAX', 'Dest_JFK', 'Dest_JNU', 'Dest_KOA', 'Dest_KTN', 'Dest_LAN', 'Dest_LAS', 'Dest_LAW', 'Dest_LAX', 'Dest_LBB', 'Dest_LCH', 'Dest_LEX', 'Dest_LFT', 'Dest_LGA', 'Dest_LGB', 'Dest_LIH', 'Dest_LIT', 'Dest_LMT', 'Dest_LNK', 'Dest_LRD', 'Dest_LSE', 'Dest_LWS', 'Dest_MAF', 'Dest_MBS', 'Dest_MCI', 'Dest_MCO', 'Dest_MDT', 'Dest_MDW', 'Dest_MEI', 'Dest_MEM', 'Dest_MFE', 'Dest_MFR', 'Dest_MGM', 'Dest_MHT', 'Dest_MIA', 'Dest_MKE', 'Dest_MLB', 'Dest_MLI', 'Dest_MLU', 'Dest_MOB', 'Dest_MOD', 'Dest_MOT', 'Dest_MQT', 'Dest_MRY', 'Dest_MSN', 'Dest_MSO', 'Dest_MSP', 'Dest_MSY', 'Dest_MTJ', 'Dest_MYR', 'Dest_OAJ', 'Dest_OAK', 'Dest_OGG', 'Dest_OKC', 'Dest_OMA', 'Dest_OME', 'Dest_ONT', 'Dest_ORD', 'Dest_ORF', 'Dest_OTH', 'Dest_OTZ', 'Dest_OXR', 'Dest_PBI', 'Dest_PDX', 'Dest_PFN', 'Dest_PHF', 'Dest_PHL', 'Dest_PHX', 'Dest_PIA', 'Dest_PIH', 'Dest_PIT', 'Dest_PMD', 'Dest_PNS', 'Dest_PSC', 'Dest_PSE', 'Dest_PSG', 'Dest_PSP', 'Dest_PVD', 'Dest_PWM', 'Dest_RAP', 'Dest_RDD', 'Dest_RDM', 'Dest_RDU', 'Dest_RHI', 'Dest_RIC', 'Dest_RKS', 'Dest_RNO', 'Dest_ROA', 'Dest_ROC', 'Dest_ROW', 'Dest_RST', 'Dest_RSW', 'Dest_SAN', 'Dest_SAT', 'Dest_SAV', 'Dest_SBA', 'Dest_SBN', 'Dest_SBP', 'Dest_SCC', 'Dest_SCE', 'Dest_SDF', 'Dest_SEA', 'Dest_SFO', 'Dest_SGF', 'Dest_SGU', 'Dest_SHV', 'Dest_SIT', 'Dest_SJC', 'Dest_SJU', 'Dest_SLC', 'Dest_SMF', 'Dest_SMX', 'Dest_SNA', 'Dest_SPI', 'Dest_SRQ', 'Dest_STL', 'Dest_SUN', 'Dest_SWF', 'Dest_SYR', 'Dest_TEX', 'Dest_TLH', 'Dest_TOL', 'Dest_TPA', 'Dest_TRI', 'Dest_TUL', 'Dest_TUS', 'Dest_TVC', 'Dest_TWF', 'Dest_TXK', 'Dest_TYR', 'Dest_TYS', 'Dest_VLD', 'Dest_VPS', 'Dest_WRG', 'Dest_XNA', 'Dest_YAK', 'Dest_YUM', 'Dest_nan']\n"
     ]
    }
   ],
   "source": [
    "dtype = {'CancellationCode': str}\n",
    "df = pd.read_csv('airline_dec_2008_50k.csv', dtype=dtype, low_memory=False)\n",
    "\n",
    "# Удаляем ненужные столбцы\n",
    "df = df.drop(['TailNum', 'Year'], axis=1)\n",
    "\n",
    "# Создаем фиктивные переменные для категориальных данных\n",
    "dummy_columns = ['UniqueCarrier', 'Origin', 'Dest']\n",
    "df = pd.get_dummies(df, columns=dummy_columns, dummy_na=True)\n",
    "\n",
    "# Удаляем столбец 'CancellationCode'\n",
    "df = df.drop(['CancellationCode'], axis=1)\n",
    "\n",
    "# Вычисляем корреляцию с целевой переменной 'Cancelled'\n",
    "correlation_with_target = df.corr()['Cancelled'].sort_values(ascending=False)\n",
    "print(\"Корреляция с целевой переменной (Cancelled):\")\n",
    "print(correlation_with_target)\n",
    "\n",
    "# Порог корреляции\n",
    "correlation_threshold = 0.5\n",
    "\n",
    "# Выбираем признаки с корреляцией выше порога\n",
    "highly_correlated_features = correlation_with_target[abs(correlation_with_target) > correlation_threshold].index.tolist()\n",
    "print(f\"\\nПризнаки с корреляцией выше {correlation_threshold}: {highly_correlated_features}\")\n",
    "\n",
    "# Удаляем высоко коррелированные признаки\n",
    "df = df.drop(highly_correlated_features, axis=1)\n",
    "print(f\"\\nПосле удаления высоко коррелированных признаков: {df.columns.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**15. (1 балл)** Приведем данные к виду, пригодному для обучения линейных моделей. Для этого вещественные признаки надо отмасштабировать, а категориальные — привести к числовому виду. Также надо устранить пропуски в данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Некоторые из признаков в нашем датасете являются категориальными. Типичным подходом к работе с ними является бинарное, или [one-hot-кодирование](https://en.wikipedia.org/wiki/One-hot).\n",
    "\n",
    "Реализуйте функцию transform_data, которая принимает на вход DataFrame с признаками и выполняет следующие шаги:\n",
    "1. Замена пропущенных значений на нули для вещественных признаков и на строки 'nan' для категориальных.\n",
    "2. Масштабирование вещественных признаков с помощью [StandardScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html).\n",
    "3. One-hot-кодирование категориальных признаков с помощью [DictVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.DictVectorizer.html) или функции [pd.get_dummies](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html).\n",
    "\n",
    "Метод должен возвращать преобразованный DataFrame, который должна состоять из масштабированных вещественных признаков и закодированных категориальных (исходные признаки должны быть исключены из выборки)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-26T06:03:38.961176600Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def transform_data(df):\n",
    "    # Замена пропущенных значений\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == 'object':  # категориальные признаки\n",
    "            df[column] = df[column].fillna('nan')\n",
    "        else:  # вещественные признаки\n",
    "            df[column] = df[column].fillna(0)\n",
    "    \n",
    "    # Определение вещественных и категориальных признаков\n",
    "    numeric_columns = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    # Масштабирование вещественных признаков\n",
    "    scaler = StandardScaler()\n",
    "    df[numeric_columns] = scaler.fit_transform(df[numeric_columns])\n",
    "    \n",
    "    # One-hot кодирование категориальных признаков\n",
    "    df_encoded = pd.get_dummies(df, columns=categorical_columns, drop_first=True)\n",
    "    \n",
    "    return df_encoded\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примените функцию transform_data к данным. Сколько признаков получилось после преобразования?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-26T06:03:38.976812900Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  Year  Month  DayofMonth  DayOfWeek   DepTime  CRSDepTime  \\\n",
      "0   -1.732016   0.0    0.0   -1.319756  -1.426318 -1.070215    0.042399   \n",
      "1   -1.731947   0.0    0.0   -1.319756  -1.426318 -1.070215    0.042399   \n",
      "2   -1.731878   0.0    0.0   -1.319756  -1.426318 -1.070215    0.042399   \n",
      "3   -1.731808   0.0    0.0   -1.319756  -1.426318 -1.070215    0.042399   \n",
      "4   -1.731739   0.0    0.0   -1.319756  -1.426318 -1.070215    0.042399   \n",
      "\n",
      "    ArrTime  CRSArrTime  FlightNum  ...  Dest_TYS  Dest_VLD  Dest_VPS  \\\n",
      "0 -1.207053    0.046675  -1.217388  ...     False     False     False   \n",
      "1 -1.207053    0.066854  -0.222447  ...     False     False     False   \n",
      "2 -1.207053    0.097123   0.265575  ...     False     False     False   \n",
      "3 -1.207053    0.302952   1.127762  ...     False     False     False   \n",
      "4 -1.207053    0.302952  -0.560708  ...     False     False     False   \n",
      "\n",
      "   Dest_WRG  Dest_XNA  Dest_YAK  Dest_YUM  CancellationCode_B  \\\n",
      "0     False     False     False     False               False   \n",
      "1     False     False     False     False               False   \n",
      "2     False     False     False     False                True   \n",
      "3     False     False     False     False               False   \n",
      "4     False     False     False     False                True   \n",
      "\n",
      "   CancellationCode_C  CancellationCode_nan  \n",
      "0               False                 False  \n",
      "1               False                 False  \n",
      "2               False                 False  \n",
      "3                True                 False  \n",
      "4               False                 False  \n",
      "\n",
      "[5 rows x 4842 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('airline_dec_2008_50k.csv', low_memory=False)\n",
    "\n",
    "transformed_df = transform_data(df)\n",
    "\n",
    "print(transformed_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**16. (0.5 балла)** Разбейте выборку и вектор целевой переменной на обучение и контроль в отношении 70/30 (для этого можно использовать, например, функцию [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.train_test_split.html)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-26T06:03:38.976812900Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер обучающей выборки: (35000, 4841)\n",
      "Размер контрольной выборки: (15000, 4841)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Загрузка данных\n",
    "df = pd.read_csv('airline_dec_2008_50k.csv', low_memory=False)\n",
    "\n",
    "# Преобразование данных\n",
    "transformed_df = transform_data(df)\n",
    "\n",
    "# Определение целевой переменной (например, 'Cancelled')\n",
    "X = transformed_df.drop('Cancelled', axis=1)  # Признаки\n",
    "y = transformed_df['Cancelled']  # Целевая переменная\n",
    "\n",
    "# Разбиение на обучающую и контрольную выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Проверка размеров выборок\n",
    "print(f\"Размер обучающей выборки: {X_train.shape}\")\n",
    "print(f\"Размер контрольной выборки: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-learn\n",
    "\n",
    "<img src = \"https://pp.vk.me/c4534/u35727827/93547647/x_d31c4463.jpg\">\n",
    "Теперь, когда мы привели данные к пригодному виду, попробуем решить задачу при помощи метода наименьших квадратов. Напомним, что данный метод заключается в оптимизации функционала $MSE$:\n",
    "\n",
    "$$MSE(X, y) = \\frac{1}{l} \\sum_{i=1}^l (<w, x_i> - y_i)^2 \\to \\min_{w},$$\n",
    "\n",
    "где $\\{ (x_i, y_i ) \\}_{i=1}^l$ — обучающая выборка, состоящая из $l$ пар объект-ответ.\n",
    "\n",
    "Заметим, что решение данной задачи уже реализовано в модуле sklearn в виде класса [LinearRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression).\n",
    "\n",
    "**17. (0.5 балла)** Обучите линейную регрессию на 1000 объектах из обучающей выборки и выведите значения $MSE$ и $R^2$ на этой подвыборке и контрольной выборке (итого 4 различных числа). Проинтерпретируйте полученный результат — насколько качественные прогнозы строит полученная модель? Какие проблемы наблюдаются в модели?\n",
    "\n",
    "**Подсказка**: изучите значения полученных коэффициентов $w$, сохраненных в атрибуте coef_ объекта LinearRegression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-26T06:03:38.976812900Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE на обучающей выборке: 1.9316174906458605e-29\n",
      "R^2 на обучающей выборке: 1.0\n",
      "MSE на контрольной выборке: 2.0824070787787003e-29\n",
      "R^2 на контрольной выборке: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(f'MSE на обучающей выборке: {mse_train}')\n",
    "print(f'R^2 на обучающей выборке: {r2_train}')\n",
    "print(f'MSE на контрольной выборке: {mse_test}')\n",
    "print(f'R^2 на контрольной выборке: {r2_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Для решения описанных вами в предыдущем пункте проблем используем L1- или L2-регуляризацию, тем самым получив Lasso и Ridge регрессии соответственно и изменив оптимизационную задачу одним из следующих образов:\n",
    "$$MSE_{L1}(X, y) = \\frac{1}{l} \\sum_{i=1}^l (<w, x_i> - y_i)^2 + \\alpha ||w||_1 \\to \\min_{w},$$\n",
    "$$MSE_{L2}(X, y) = \\frac{1}{l} \\sum_{i=1}^l (<w, x_i> - y_i)^2 + \\alpha ||w||_2^2 \\to \\min_{w},$$\n",
    "\n",
    "где $\\alpha$ — коэффициент регуляризации. Один из способов его подбора заключается в переборе некоторого количества значений и оценке качества на кросс-валидации для каждого из них, после чего выбирается значение, для которого было получено наилучшее качество.\n",
    "\n",
    "**18. (0.5 балла)** Обучите линейные регрессии с L1- и L2-регуляризатором, подобрав лучшее значение параметра регуляризации из списка alpha_grid при помощи кросс-валидации c 5 фолдами на тех же 1000 объектах, что и в п.17. Выведите значения $MSE$ и $R^2$ на обучающей и контрольной выборках. Удалось ли решить указанные вами ранее проблемы?\n",
    "\n",
    "Для выполнения данного задания вам могут понадобиться реализованные в библиотеке объекты [LassoCV](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html), [RidgeCV](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html) и [KFold](http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.KFold.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-26T06:03:38.976812900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso:\n",
      "Optimal alpha: 0.01\n",
      "MSE on training set: 0.001467658090123241\n",
      "R^2 on training set: 0.9985291822774842\n",
      "MSE on test set: 0.001496320908906144\n",
      "R^2 on test set: 0.9985109976337726\n",
      "Ridge:\n",
      "Optimal alpha: 0.01\n",
      "MSE on training set: 6.123424149629436e-11\n",
      "R^2 on training set: 0.999999999938634\n",
      "MSE on test set: 9.71521897321439e-11\n",
      "R^2 on test set: 0.999999999903323\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV, RidgeCV, Lasso, Ridge\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "alpha_grid = [0.01, 0.1, 1]  # Уменьшенное число гиперпараметров\n",
    "\n",
    "kf = KFold(n_splits=3)  # Уменьшенное число разбиений\n",
    "\n",
    "lasso_cv = LassoCV(alphas=alpha_grid, cv=kf, n_jobs=-1)\n",
    "ridge_cv = RidgeCV(alphas=alpha_grid, cv=kf)\n",
    "\n",
    "lasso_cv.fit(X_train, y_train)\n",
    "ridge_cv.fit(X_train, y_train)\n",
    "\n",
    "best_alpha_lasso = lasso_cv.alpha_\n",
    "best_alpha_ridge = ridge_cv.alpha_\n",
    "\n",
    "lasso_model = Lasso(alpha=best_alpha_lasso)\n",
    "ridge_model = Ridge(alpha=best_alpha_ridge)\n",
    "\n",
    "lasso_model.fit(X_train, y_train)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred_lasso = lasso_model.predict(X_train)\n",
    "y_test_pred_lasso = lasso_model.predict(X_test)\n",
    "y_train_pred_ridge = ridge_model.predict(X_train)\n",
    "y_test_pred_ridge = ridge_model.predict(X_test)\n",
    "\n",
    "mse_train_lasso = mean_squared_error(y_train, y_train_pred_lasso)\n",
    "r2_train_lasso = r2_score(y_train, y_train_pred_lasso)\n",
    "mse_test_lasso = mean_squared_error(y_test, y_test_pred_lasso)\n",
    "r2_test_lasso = r2_score(y_test, y_test_pred_lasso)\n",
    "\n",
    "mse_train_ridge = mean_squared_error(y_train, y_train_pred_ridge)\n",
    "r2_train_ridge = r2_score(y_train, y_train_pred_ridge)\n",
    "mse_test_ridge = mean_squared_error(y_test, y_test_pred_ridge)\n",
    "r2_test_ridge = r2_score(y_test, y_test_pred_ridge)\n",
    "\n",
    "print(f\"Lasso:\")\n",
    "print(f\"Optimal alpha: {best_alpha_lasso}\")\n",
    "print(f\"MSE on training set: {mse_train_lasso}\")\n",
    "print(f\"R^2 on training set: {r2_train_lasso}\")\n",
    "print(f\"MSE on test set: {mse_test_lasso}\")\n",
    "print(f\"R^2 on test set: {r2_test_lasso}\")\n",
    "\n",
    "print(f\"Ridge:\")\n",
    "print(f\"Optimal alpha: {best_alpha_ridge}\")\n",
    "print(f\"MSE on training set: {mse_train_ridge}\")\n",
    "print(f\"R^2 on training set: {r2_train_ridge}\")\n",
    "print(f\"MSE on test set: {mse_test_ridge}\")\n",
    "print(f\"R^2 on test set: {r2_test_ridge}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Градиентный спуск\n",
    "\n",
    "В предыдущем разделе мы использовали существующие реализации методов обучения линейной регрессии с регуляризацией и без. Тем не менее, подобные реализации, как правило, имеются лишь для ограниченного набора стандартных методов. В частности, при выходе функционала качества за пределы стандартного множества необходимо самостоятельно реализовывать составляющие процесса решения оптимизационной задачи. Именно этому и посвящен данный раздел задания.\n",
    "\n",
    "Пусть необходимо минимизировать следующий функционал (Mean Square Percentage Error — модифицированный [RMSPE](https://www.kaggle.com/c/rossmann-store-sales/details/evaluation)):\n",
    "$$MSPE(\\{x_i, y_i\\}_{i=1}^l, \\, w) = \\frac{1}{l}\\sum_{i=1}^l \\left( \\frac{y_i - \\langle w, x_i \\rangle }{y_i} \\right)^2,$$\n",
    "\n",
    "где $\\{x_i, y_i\\}_{i=1}^l$ — обучающая выборка, $w$ — вектор весов линейной модели. Будем также рассматривать функционал $MSPE$ с L2-регуляризацией:\n",
    "\n",
    "$$MSPE(\\{x_i, y_i\\}_{i=1}^l, \\, w) = \\frac{1}{l}\\sum_{i=1}^l \\left( \\frac{y_i - \\langle w, x_i \\rangle }{y_i} \\right)^2 + ||w||_2^2.$$\n",
    "\n",
    "**19. (0 баллов)** Добавьте к объектам обеих выборок из п. 16 единичный признак."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-26T06:03:38.976812900Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train['constant_feature'] = 1\n",
    "\n",
    "X_test['constant_feature'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**20. (1 балл)** Реализуйте функции, которые вычисляют:\n",
    " * прогнозы линейной модели;\n",
    " * функционал $MSPE$ и его градиент;\n",
    " * регуляризованный $MSPE$ и его градиент."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-26T06:03:38.976812900Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def linear_model_predict(X, weights):\n",
    "    return np.dot(X, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-26T06:03:38.976812900Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_squared_prediction_error(y_true, y_pred):\n",
    "    n_samples = len(y_true)\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "def mspe_gradient(y_true, y_pred, X):\n",
    "    n_samples = len(y_true)\n",
    "    error = y_true - y_pred\n",
    "    gradient = -2 * np.dot(error, X) / n_samples\n",
    "    return gradient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-26T06:03:38.976812900Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def regularized_mspe(y_true, y_pred, X, weights, alpha):\n",
    "    n_samples = len(y_true)\n",
    "    mse = mean_squared_prediction_error(y_true, y_pred)\n",
    "    regularization_term = alpha * np.sum(weights ** 2)\n",
    "    return mse + regularization_term\n",
    "\n",
    "def regularized_mspe_gradient(y_true, y_pred, X, weights, alpha):\n",
    "    n_samples = len(y_true)\n",
    "    error = y_true - y_pred\n",
    "    gradient = -2 * np.dot(error, X) / n_samples + 2 * alpha * weights\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-26T06:03:38.976812900Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_pred(X, w):\n",
    "    return np.dot(X, w)\n",
    "\n",
    "def get_reg_func(w, X, y, alpha):\n",
    "    mse = mean_squared_percentage_error(y, make_pred(X, w))\n",
    "    regularization_term = alpha * np.sum(w**2)\n",
    "    return mse + regularization_term\n",
    "\n",
    "def mean_squared_percentage_error(y_true, y_pred):\n",
    "    return ((y_true - y_pred) ** 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-26T06:03:38.992426900Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_pred(X, w):\n",
    "    return np.dot(X, w)\n",
    "\n",
    "def get_reg_grad(w, X, y, alpha):\n",
    "    mse_grad = gradient_mspe(y, make_pred(X, w), X)\n",
    "    regularization_grad = 2 * alpha * w\n",
    "    return mse_grad + regularization_grad\n",
    "\n",
    "def gradient_mspe(y_true, y_pred, X):\n",
    "    n = len(y_true)\n",
    "    grad = -2/n * X.T.dot((y_true - y_pred) / y_true)\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Предсказания: [0.54165218 0.15568047 0.45667031 0.12995866 0.21298795 0.19108169\n",
      " 0.21796447 0.17428551 0.45132547 0.35770364]\n",
      "MSPE: 0.1850541820865908\n",
      "Градиент MSPE: [-0.30115822 -0.06496132 -0.2290999 ]\n",
      "Регуляризованный MSPE: 0.2111817894321774\n",
      "Градиент регуляризованного MSPE: [-0.27675057  0.03407406 -0.22222219]\n",
      "Предсказания (make_pred): [0.54165218 0.15568047 0.45667031 0.12995866 0.21298795 0.19108169\n",
      " 0.21796447 0.17428551 0.45132547 0.35770364]\n",
      "Mean Squared Percentage Error: 0.1850541820865908\n",
      "Регуляризованный функционал: 0.2111817894321774\n",
      "Градиент регуляризованного функционала: [-0.25720494  0.98909033  0.44347081]\n"
     ]
    }
   ],
   "source": [
    "# Задание входных данных\n",
    "np.random.seed(42)\n",
    "X = np.random.rand(10, 3)  # 10 образцов, 3 признака\n",
    "y_true = np.random.rand(10)  # 10 истинных значений\n",
    "weights = np.random.rand(3)  # Веса модели\n",
    "alpha = 0.1  # Коэффициент регуляризации\n",
    "\n",
    "y_pred = linear_model_predict(X, weights)\n",
    "mspe = mean_squared_prediction_error(y_true, y_pred)\n",
    "grad = mspe_gradient(y_true, y_pred, X)\n",
    "reg_mspe = regularized_mspe(y_true, y_pred, X, weights, alpha)\n",
    "reg_grad = regularized_mspe_gradient(y_true, y_pred, X, weights, alpha)\n",
    "pred = make_pred(X, weights)\n",
    "mse_perc_error = mean_squared_percentage_error(y_true, y_pred)\n",
    "reg_func = get_reg_func(weights, X, y_true, alpha)\n",
    "reg_grad_func = get_reg_grad(weights, X, y_true, alpha)\n",
    "\n",
    "# Вывод результатов\n",
    "print(\"Предсказания:\", y_pred)\n",
    "print(\"MSPE:\", mspe)\n",
    "print(\"Градиент MSPE:\", grad)\n",
    "print(\"Регуляризованный MSPE:\", reg_mspe)\n",
    "print(\"Градиент регуляризованного MSPE:\", reg_grad)\n",
    "print(\"Предсказания (make_pred):\", pred)\n",
    "print(\"Mean Squared Percentage Error:\", mse_perc_error)\n",
    "print(\"Регуляризованный функционал:\", reg_func)\n",
    "print(\"Градиент регуляризованного функционала:\", reg_grad_func)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
