# SSD: Single Shot MultiBox Detector

## Кто предложил

Liu, W. et al. (2016). SSD: Single Shot MultiBox Detector. In: Leibe, B., Matas, J., Sebe, N., Welling, M. (eds) Computer Vision – ECCV 2016. ECCV 2016. Lecture Notes in Computer Science(), vol. 9905. Springer, Cham. DOI: [10.1007/978-3-319-46448-0_2](https://doi.org/10.1007/978-3-319-46448-0_2){:target="_blank"}. URL: [https://arxiv.org/abs/1512.02325](https://arxiv.org/abs/1512.02325){:target="_blank"}.

## Описание модели

![architecture]({{ site.baseurl }}/artificial-intelligence/pattern-recognition/labs/lab3_data/SSD_architecture.svg)

Мы представляем метод обнаружения объектов на изображениях с использованием одной глубокой нейронной сети. Наш подход, названный SSD, дискретизирует выходное пространство ограничивающих рамок в набор рамок по умолчанию с различными соотношениями сторон и масштабами для каждого местоположения карты признаков. Во время прогнозирования сеть генерирует оценки наличия каждой категории объектов в каждой рамке по умолчанию и вносит корректировки в рамку для лучшего соответствия форме объекта. Кроме того, сеть объединяет прогнозы из нескольких карт признаков с различными разрешениями для естественной обработки объектов различных размеров. Наша модель SSD проста по сравнению с методами, требующими предложений объектов, поскольку она полностью исключает генерацию предложений и последующую стадию повторной выборки пикселей или признаков и инкапсулирует все вычисления в одной сети. Это делает SSD простым в обучении и простым в интеграции в системы, требующие компонента обнаружения. Экспериментальные результаты на наборах данных PASCAL VOC, MS COCO и ILSVRC подтверждают, что SSD имеет сопоставимую точность с методами, которые используют дополнительный шаг предложения объектов, и намного быстрее, обеспечивая при этом единую структуру как для обучения, так и для вывода. По сравнению с другими одноступенчатыми методами, SSD имеет гораздо лучшую точность, даже при меньшем размере входного изображения. Для входного изображения 300×300 SSD достигает 72,1% mAP на тесте VOC2007 при 58 FPS на Nvidia Titan X, а для входного изображения 500×500 SSD достигает 75,1% mAP, превосходя сопоставимую современную модель Faster R-CNN.


SSD (Single Shot MultiBox Detector) — это архитектура для обнаружения объектов на изображениях, которая отличается высокой скоростью и приемлемой точностью. Основное преимущество SSD заключается в том, что она выполняет обнаружение объектов за один проход через нейронную сеть, без необходимости в дополнительных этапах, таких как генерация предложений регионов, как это делается в более сложных моделях типа Faster R-CNN.

## Как работает SSD
1. Извлечение признаков (Feature Extraction): На первом этапе изображение пропускается через базовую сверточную нейронную сеть (например, VGG16 или другую), которая извлекает пространственные признаки на разных уровнях глубины.
2. Предсказание ограничивающих рамок и классов (Bounding Boxes and Class Predictions): На нескольких уровнях карты признаков (т.е. на разных масштабах) сеть предсказывает ограничивающие рамки (боксы) и вероятность принадлежности к каждому из классов объектов для каждого бокса. Это позволяет обнаруживать объекты разных размеров.
3. Рамки по умолчанию (Default Boxes): Для каждого местоположения на карте признаков сеть использует набор заранее определенных рамок по умолчанию с различными соотношениями сторон и масштабами. Эти рамки сравниваются с объектами на изображении, и сеть корректирует их положение и размер для лучшего соответствия реальным объектам.
4. Постобработка с использованием NMS (Non-Maximum Suppression): После предсказания большое количество рамок может пересекаться. Метод подавления немаксимумов (NMS) используется для удаления избыточных рамок, оставляя только наиболее вероятные предсказания.

## Применение:
1. Автономное вождение: Быстрое обнаружение объектов на дороге, таких как пешеходы, транспортные средства и дорожные знаки.
2. Видеонаблюдение и безопасность: Мониторинг в реальном времени для обнаружения подозрительных объектов или действий.
3. Обработка изображений в реальном времени: Приложения, требующие мгновенного обнаружения объектов, такие как дополненная реальность.
 
 ## Архитектура сети SSD

![SSD (вверху) против YOLO (внизу)](архитектура.webp)
На изображении представлены архитектуры двух популярных моделей для обнаружения объектов — SSD (сверху) и YOLO (снизу). Вот описание каждого элемента и пояснение выделенных частей:
Архитектура SSD
1. VGG-16: Входное изображение размером 300x300 проходит через сверточную сеть VGG-16 до слоя Conv5_3, который используется для извлечения признаков.
2. Дополнительные слои признаков (Extra Feature Layers): После VGG-16 добавляются слои для извлечения дополнительных признаков на разных масштабах, что позволяет SSD обнаруживать объекты разных размеров.
3. Свертки 3x3 (3x3 Conv): На изображении отмечены сверточные слои с ядром 3x3, которые используются для классификации и предсказания границ объектов.
4. 4 рамки (4 boxes): Поясняется, что модель предсказывает до 4 ограничивающих рамок для каждого местоположения.
5. Количество классов (No. of Classes): Параметр, указывающий количество классов объектов, которые может обнаружить модель.
6. 4 смещения (4 offsets): Смещения, которые используются для предсказания координат рамок.
7. Детекции: 8732 на класс: Всего для каждого класса выполняется 8732 детекции.
8. Подавление немаксимумов (Non-Maximum Suppression): Метод, используемый для выбора окончательных предсказаний, отбрасывая перекрывающиеся рамки.
9. Результаты: SSD достигает 74.3 mAP (средняя точность) и работает со скоростью 59 кадров в секунду (FPS).

Архитектура YOLO
1. Входное изображение: Размер изображения составляет 448x448 пикселей.
2. Настроенная архитектура YOLO: Использует несколько сверточных и полностью связанных слоев для обработки изображения и предсказания объектов в сетке 7x7.
3. Детекции: 98 на класс: YOLO выполняет 98 предсказаний на каждый класс.
4. Подавление немаксимумов: Используется для отбора лучших предсказаний.
5. Результаты: YOLO достигает 63.4 mAP (средняя точность)  и работает со скоростью 45 кадров в секунду (FPS).
## Функция потерь
\[
L(x, c, l, g) = \frac{1}{N} \left( L_{\text{conf}}(x, c) + \alpha L_{\text{loc}}(x, l, g) \right)
\]
Функция потерь состоит из двух членов: Lconf и Lloc, где N — это количество стандартных рамок, которые были сопоставлены с реальными объектами. Эти потери взвешиваются и комбинируются, чтобы обучить модель как можно точнее распознавать объекты.

Потеря локализации
\[
L_{\text{loc}}(x, l, g) = \sum_{i \in \text{Pos}} \sum_{m \in \{cx, cy, w, h\}} x_{ij}^k \text{smooth}_{L_1}(l_i^m - \hat{g}_j^m)
\]

\[
\hat{g}_j^{cx} = \frac{(g_j^{cx} - d_i^{cx})}{d_i^w}, \quad \hat{g}_j^{cy} = \frac{(g_j^{cy} - d_i^{cy})}{d_i^h}
\]

\[
\hat{g}_j^w = \log \left( \frac{g_j^w}{d_i^w} \right), \quad \hat{g}_j^h = \log \left( \frac{g_j^h}{d_i^h} \right)
\]

Это гладкая L1-потеря между предсказанной рамкой (l) и истинной рамкой (g). Рассчитывается по параметрам смещений центра (cx, cy), ширины (w) и высоты (h) ограничивающей рамки. Цель — научить модель точно предсказывать координаты рамок объектов. Эта потеря аналогична используемой в модели Faster R-CNN.

Потеря уверенности
\[
L_{\text{conf}}(x, c) = - \sum_{i \in \text{Pos}} x_{ij}^p \log(\hat{c}_i^p) - \sum_{i \in \text{Neg}} \log(\hat{c}_i^0) \quad \text{где} \quad \hat{c}_i^p = \frac{\exp(c_i^p)}{\sum_p \exp(c_i^p)}
\]

Это потеря softmax, которая вычисляется по уверенности в разных классах. Модель должна отличать правильные объекты от фона, и эта функция помогает ей быть уверенной в своих предсказаниях. Положительные примеры (объекты) и отрицательные примеры (фон) используются для вычисления этой потери.

Эти формулы применяются во время обучения модели SSD.


## Некоторые подробности обучения

#### Отбор сложных отрицательных примеров

Вместо того чтобы использовать все отрицательные примеры (то есть примеры, где модель ошибочно распознала объект), мы сортируем их по значению потерь уверенности для каждой стандартной рамки. Затем выбираем самые сложные примеры (те, у которых наибольшие потери), так чтобы соотношение между отрицательными и положительными примерами не превышало 3:1.
Это помогает ускорить оптимизацию и делает обучение модели более стабильным.

#### Аугментация данных
Аугментация данных — это метод, который используется в машинном обучении для увеличения объёма тренировочных данных. Он особенно полезен при работе с изображениями, чтобы модель могла лучше обобщать и распознавать объекты в разных условиях.

Для каждого тренировочного изображения случайным образом выбирается один из вариантов:
1. Использовать всё исходное изображение полностью.
2. Взять фрагмент изображения так, чтобы перекрытие с объектами составляло 0.1, 0.3, 0.5, 0.7 или 0.9.
3. Случайно выбрать фрагмент изображения.

Размер выбранного фрагмента варьируется от 0.1 до 1 (или может быть равен размеру всего изображения), а соотношение сторон меняется от 1/2 до 2. После этих действий каждый фрагмент изменяется до фиксированного размера, и с вероятностью 50% он может быть перевёрнут по горизонтали. Также применяются фотометрические искажения для изменения яркости, контрастности и других характеристик изображения.

## Фреймворк размещенный авторами на GitHub 

[исходники](https://github.com/weiliu89/caffe/tree/ssd)

## Пример работы

![Некоторые результаты обнаружения в наборе данных MS COCO](image-3.png)